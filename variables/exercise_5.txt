

x = 0
3.times do
  x += 1
end
puts x

y = 0
3.times do
  y += 1
  x = y
end
puts x

What does x print to the screen in each case? Do they both give errors? Are the errors different? Why?

Program1 runs fine and outputs 3.

Pogram2 should generate an undefined local variable error as the reference to x occurs out of scope.